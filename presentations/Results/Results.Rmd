---
title: "Results"
header-includes:
- \usepackage{caption}
- \captionsetup[figure]{labelformat=empty}
output:
  pdf_document:
    keep_tex: yes
  word_document: default
bibliography: references.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,
                      message = F, 
                      warning = F)

library("kableExtra")
library("tidyverse")
library("ggpubr")

# Global Variables-------------
new_cases.threshold = 10
```

<!---
## Methods

(with the number of successes being $n_{t+D}$ and the total number of trials being $n_{t}$ + $n_{t+D}$) using the Clopperâ€“Pearson method, as implemented in the `poisson.test()` function in the `stats` package for the R programming language [@rcoreteamLanguageEnvironmentStatistical2020].
--->

## A Simple Ratio for Estimating $R_t$

If we assume that the generation interval has very little variance (i.e. the time between a primary and secondary infection is most often equal to the mean of the generation interval distribution), then the $R_t$ on day $t$ can be estimated as the ratio of the number of new cases ($I$) on day $t+D$ and day $t$, where $D$ is equal to the mean generation interval. 

$$R_t \approx \frac{I_{t+D}}{I_t}$$

However, relying on reported new cases violates this assumption for two reasons. First, the actual transmission of the virus doesn't conform to a rigid schedule. Two, there is inevitable variance in the timing of when new cases are reported (e.g. new cases are typically reported less over weekends). We can handle these two violations of the assumption by estimating $R_t$ as the ratio of the sums of new cases within two time periods size $\tau$ days (with the center of the time periods being on days $t$ and $t+D$). By considering the sum of new cases within larger time periods (e.g. 7 days), we capture secondary infections that didn't occur exactly $D$ days from the primary infection and we also counteract the variation in new case reporting. 

$$ R_t \approx \frac{\sum_{t - \frac{\tau}{2} + D}^{t + \frac{\tau}{2} + D}I_i}{\sum_{t - \frac{\tau}{2}}^{t + \frac{\tau}{2}}I_i} = \frac{n_{t+D}}{n_t}$$

Assuming that the number of new cases that occur each day is a poisson process, then we can consider $R_t$ as the ratio of two poisson rates. Thus, a 95% confidence interval for $R_t$ can be calculated as a binomial proportion confidence interval (see Methods for more details). 

<!---
Since it is nearly impossible for any public health programs to identify all new cases of infection each day, the reported new cases represent only a subset of the total cases. For estimation $R_t$ to be accurate, it depends on how this subset is selected in a few ways. First, the porportion of the total represented by this subset cannot change drastically between the two reporting periods (e.g. if the porportion of the population that is tested drastically increases between the two reporting periods, then $R_t$ will appear artificially inflated). Second, the demographics that influence susceptibility to the disease (or testing positive) of the people reported cannot change drastically between the reporting periods (e.g. only testing the elderly in one time period, and then switching to testing non-elderly will likely affect $R_t$ estimations). Third, ultimately the change in cases of the subset needs to reflect the rate of change of the entire population (e.g. if...)
--->

```{r}
tbl_1 = read_csv("table_1 - Description of Rt Estimation Methods.csv")

tbl_1 %>%
kable(., "latex", align="l", booktabs=TRUE, escape = F, caption = "Methods for Estimating $R_t$") %>%
  kable_styling(full_width = F)%>%
  column_spec(1, width = "8em", bold = T, color = "black")%>%
  column_spec(2, width = "28em") %>%
  column_spec(3, width = "8em")
```

## Performance of the Simple Ratio estimation of $R_t$

To assess the performance of this simple ratio method, we used a Susceptible - Exposed - Infectious - Recovered (SEIR) model[] to generate simulated epidemics in which there is a known $R_t$ and then determined how well the simple ratio method can estimate the $R_t$ compared to the commonly used Cori et al method (**Table 1**)[@coriNewFrameworkSoftware2013].

```{r set_parameters}
Npop = 1e6
i.start = 10
r0_initial = 2.5
intialOutbreak_length = 50
r0_lockdown = 0.9
lockdown_length = 50
r0_reopening = 1.8
reopening_length = 50
  
PARAMS <- list(
  ndays = intialOutbreak_length + lockdown_length + 100,
  R0_vector = c(r0_initial, r0_initial, r0_lockdown, r0_lockdown, r0_reopening, r0_reopening),
  R0_days = c(1, intialOutbreak_length, 
              intialOutbreak_length + 7, intialOutbreak_length + lockdown_length, 
              intialOutbreak_length + lockdown_length + 7,  intialOutbreak_length + lockdown_length + 100),
  s.num = Npop - i.start,
  e.num = 0,
  i.num = i.start,
  r.num = 0,
  se.flow = 0,
  ei.flow = 0,
  ir.flow = 0, 
  d.flow = 0,
  e.dur = 3,
  i.dur = 5,
  N = Npop
)

nsimulation = 100
```

As an initial example, we simulated an epidemic with a population `r english::as.english(Npop)` people and starting with `r i.start` infectious individuals. We track the epidemic for `r PARAMS$ndays` days and we set the $R_0$ at `r r0_initial` for the first `r intialOutbreak_length` days, then `r r0_lockdown` for the next `r lockdown_length` days, and then then `r r0_reopening` for the next `r reopening_length`; thus simulating an initial outbreak, a lockdown, and re-opening scenario. **Figure 1A** demonstrates how closely the simple ratio estimates the $R_t$ and is essentially as good as the Cori et al. method. We repeated this process `r nsimulation` times using different randomly selected parameters for the epidemic. **Figure 1B** and **1C** demonstrate 2 more examples. **Figure 1D** summarizes the root-mean-square-error in $R_t$ estimation for both the simple ratio and Cori et al methods. ***.  

```{r initial_simulation}
source("../../scripts/functions_SEIR_simulation.R")
source("../../simplified_r_statistic/Estimate_R_Functions.R")

# simulate epidemic based on parameters
initial_simulation = simulate_seir_ode_wrapper(PARAMS)

# estimate r_t
calculate_rt_wrapper <- function(simulation, e.dur, i.dur, si_sd, tau) {
  
  si_mean = e.dur + i.dur
    
  # remove incidences with NA values
  simulation = simulation %>% drop_na(incidence) 

  t = simulation$time
  Incid = simulation$incidence
  r_est.simple = EstimateR.simple(date = t, Is = Incid, si_mean = si_mean, tau=tau)
  r_est.cori = EstimateR.cori(date = t, Is = Incid, si_mean = si_mean, si_sd = si_sd, tau=tau)
  
  # combine tables
  r_est <- full_join(r_est.simple, r_est.cori, by="date")
  df <- full_join(r_est, simulation, by=c("date" = "time"))  
  df$tau = tau
  df$si_mean = si_mean
  df$si_sd = si_sd
  df$e.dur = e.dur
  df$i.dur = i.dur
  
  return(tibble(df))
}

df <- calculate_rt_wrapper(initial_simulation, 
                           e.dur = PARAMS$e.dur, i.dur = PARAMS$i.dur,
                           si_sd = 1, tau = 7)

# **********
# Figure 1A
# *********

Fig1A <- df %>% filter(date < 201) %>%
          pivot_longer(cols=c("S", "E", "I", "R"), names_to = c("pop_type"), values_to="pop") %>%
        ggplot() +
          geom_line(aes(date, pop/1000, color=pop_type)) +
          theme_bw() +
          labs(y = "population size (thousands)")

Fig1B <- df %>% filter(date < 201) %>%
          pivot_longer(cols=contains(".R_"), names_to = c("Method", ".value"), names_sep=".R_") %>%
          mutate(Method = factor(Method, levels=c("simple", "cori"))) %>%
        ggplot() +  
          geom_line(aes(date, true_rt, group=Method)) +
          geom_ribbon(aes(x=date, ymin=Quantile_025, ymax=Quantile_975, fill=Method, group=Method), alpha=0.2) +
          geom_line(aes(x=date, y=mean, color=Method), size=1) +
          geom_hline(yintercept = 1, linetype = 2) +
          theme_bw() +
          ylim(0,5) + labs(x="time", y=expression(R[t])) + 
          theme(
            strip.background = element_blank(),
            strip.text.x = element_blank())

ggpubr::ggarrange(Fig1A, Fig1B, nrow = 2)
```


```{r}
Npop = 1e6
i.start = 10
r0_initial = 2
intialOutbreak_length = 50
r0_lockdown = 0.8
lockdown_length = 50
r0_reopening = 1.5
reopening_length = 50
  
PARAMS <- list(
  ndays = intialOutbreak_length + lockdown_length + 100,
  R0_vector = c(r0_initial, r0_initial, r0_lockdown, r0_lockdown, r0_reopening, r0_reopening),
  R0_days = c(1, intialOutbreak_length, 
              intialOutbreak_length + 7, intialOutbreak_length + lockdown_length, 
              intialOutbreak_length + lockdown_length + 7,  intialOutbreak_length + lockdown_length + 100),
  s.num = Npop - i.start,
  e.num = 0,
  i.num = i.start,
  r.num = 0,
  se.flow = 0,
  ei.flow = 0,
  ir.flow = 0, 
  d.flow = 0,
  #e.dur = 3,
  #i.dur = 5,
  N = Npop
)

PARAMS = cross2(3:5,3:5) %>% map(., function(x) c(PARAMS, e.dur=x[[1]], i.dur=x[[2]])) 
simulation <- map(PARAMS, simulate_seir_ode_wrapper)
simulations.df <- map2(simulation, PARAMS, function(x,y) calculate_rt_wrapper(x, e.dur = y$e.dur, i.dur = y$i.dur, si_sd=1, tau=1))
simulations.df <- bind_rows(simulations.df, .id="simulation")


simulations.df %>% filter(date < 201) %>%
    pivot_longer(cols=c("S", "E", "I", "R"), names_to = c("pop_type"), values_to="pop") %>%
  ggplot() +
    geom_line(aes(date, pop/10000, color=pop_type)) +
    facet_wrap(e.dur~i.dur) +
    theme_bw()

simulations.df %>% filter(date < 201) %>%
    pivot_longer(cols=contains(".R_"), names_to = c("Method", ".value"), names_sep=".R_") %>%
    mutate(Method = factor(Method, levels=c("simple", "cori"))) %>%
  ggplot() +  
    geom_line(aes(date, true_rt, group=Method)) +
    geom_ribbon(aes(x=date, ymin=Quantile_025, ymax=Quantile_975, fill=Method, group=Method), alpha=0.2) +
    geom_line(aes(x=date, y=mean, color=Method), size=1) +
    geom_hline(yintercept = 1, linetype = 2) +
    facet_wrap(e.dur~i.dur) +
    theme_bw() +
    ylim(0,5) + labs(x="time", y="Rt") #+ 
    theme(strip.background = element_blank(),
          strip.text.x = element_blank())

```

## References